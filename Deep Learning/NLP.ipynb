{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854be6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3862be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"C:\\\\Users\\\\deepak\\\\Summer Intership and Training\\\\Machine_Learning\\\\csv\\\\IMDB DataSet.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea1c364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a2a9e",
   "metadata": {},
   "source": [
    "# step 1 Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c2d4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d2785f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If I want to convert all movies review then\n",
    "df['review'] = df['review'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569aada0",
   "metadata": {},
   "source": [
    "# step-2 Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00734f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5029d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<html><body><p> Movie1 </p><p> Click here to <a href='http://google.com'>download</a></p>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb31bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Movie1  Click here to download'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95e97ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we remove tags from IMDB Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660b1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2412934d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. the filming tec...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65548b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to remove urls from text then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2feed131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+/www\\.\\S+') \n",
    "    return pattern.sub(r\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3718e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Check out my notebook https://www.deture.com/delta/note1234acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bfc75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'Check out my notebook http://www.deture.com/delta/note1234acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daa8a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = 'Google search here www.google.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40b77749",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = 'For notebook click https://www.deture.com/delta/note1234acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bb9d789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my notebook https://www.deture.com/delta/note1234acc'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af89ea50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my notebook http://www.deture.com/delta/note1234acc'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2701bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google search here www.google.com'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74d9a10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For notebook click https://www.deture.com/delta/note1234acc'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cb1eb",
   "metadata": {},
   "source": [
    "# step-4 Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7229ef8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "import time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63dd2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0981589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee362927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string With Punctuation'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"string. With. Punctuation?\"\n",
    "remove_punc(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3beef147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmlbodyp Movie1 pp Click here to a hrefhttpgooglecomdownloadap\n",
      "0.0010023117065429688\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punc(text)) \n",
    "time1 = time.time()-start \n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "865d81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070983ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d82957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6ab5033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "0      31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1      31964   @user #white #supremacists want everyone to s...\n",
       "2      31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3      31966  is the hp and the cursed child book up for res...\n",
       "4      31967    3rd #bihday to my amazing, hilarious #nephew...\n",
       "...      ...                                                ...\n",
       "17192  49155  thought factory: left-right polarisation! #tru...\n",
       "17193  49156  feeling like a mermaid ð #hairflip #neverre...\n",
       "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...\n",
       "17195  49158  happy, at work conference: right mindset leads...\n",
       "17196  49159  my   song \"so glad\" free download!  #shoegaze ...\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"C:\\\\Users\\\\deepak\\\\Summer Intership and Training\\\\Machine_Learning\\\\csv\\\\twitter_sentiment_analysis.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "775715d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72ccee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5dc4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fec7eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory leftright polarisation trump u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid ð hairflip neverread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>hillary campaigned today in ohioomg amp used w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song so glad free download  shoegaze newm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "0      31963  studiolife aislife requires passion dedication...\n",
       "1      31964   user white supremacists want everyone to see ...\n",
       "2      31965  safe ways to heal your acne    altwaystoheal h...\n",
       "3      31966  is the hp and the cursed child book up for res...\n",
       "4      31967    3rd bihday to my amazing hilarious nephew el...\n",
       "...      ...                                                ...\n",
       "17192  49155  thought factory leftright polarisation trump u...\n",
       "17193  49156  feeling like a mermaid ð hairflip neverread...\n",
       "17194  49157  hillary campaigned today in ohioomg amp used w...\n",
       "17195  49158  happy at work conference right mindset leads t...\n",
       "17196  49159  my   song so glad free download  shoegaze newm...\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd457b1",
   "metadata": {},
   "source": [
    "# step-5 Chatword Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186cc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {'u2': 'you too', 'BBL': 'Be Back Later', 'GAL': 'Get A Life'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f454e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u2': 'you too', 'BBL': 'Be Back Later', 'GAL': 'Get A Life'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "162afc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversation(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words [w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \"\".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47ab3602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get A Life'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation('GAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c2bfa",
   "metadata": {},
   "source": [
    "# step-6 Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54433d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ipip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb635e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af6fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = \"ceertain conditionas seveal ggenerations aree modified in the saame maner.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76bdfadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "textBlb = TextBlob (incorrect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c98678e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions several generations are modified in the same manner.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a159b8b8",
   "metadata": {},
   "source": [
    "# step-7 Removing StepWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13200cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\deepak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33947e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe98e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b62b79ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probablyall-timefavoritemovie,storyselflessness,sacrificededicationnoblecause.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually work\n",
    "\n",
    "def remove_stopwords (text): \n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        \n",
    "        if word in set(stopwords.words('english')):\n",
    "            new_text.append(\"\")\n",
    "        \n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \"\".join(x)\n",
    "\n",
    "\n",
    "remove_stopwords('probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d41c68",
   "metadata": {},
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53d988ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. prefix character(s) at the begining\n",
    "#2. suffix character(s) at the end = km).1\"\n",
    "#3. Infix character(s) in between --/...\n",
    "#4. Exception Special-case rule to split a string into several tokens or\n",
    "#prevent a token from being split when punctuation rules are applied. Let's U.s.\n",
    "#Approach the tokenization using the split function\n",
    "#1. word tokenization\n",
    "sent1 = \"I am going to delhi\"\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94becfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentence tokenization\n",
    "sent2 = \"I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great\"\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab7062d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhil']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problems with split function \n",
    "sent3 = \"I am going to delhil\"\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e379099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the sent3 problem there is seeing that I is include with delhi we have to remove it byre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a13f7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am going to delhi'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3 = \"I am going to delhi\"\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "sent3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c1ec8",
   "metadata": {},
   "source": [
    "# 1. NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd5f1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f086280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\deepak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc2e8bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti = \"I am going to visit delhil\" \n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26af7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = 'I have a Ph.D. in A.I.'\n",
    "sent3 = \"We 're here to help! mail us at nks@gmail.com\"\n",
    "sent4 = 'A 5km ride cost $10.50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d6e47f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D.', 'in', 'A.I', '.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize (sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34c6490a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'nks',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize (sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a46e81dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '$', '10.50']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize (sent4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd13c491",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e765d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Inflection ==> \"In grammar, inflection is the modification of a word\n",
    "# to express different grametical categories such as tense, case, voice, aspect, person, number\n",
    "#2. Stemming ==> Stemming is the process of reducing inflection in words to their root forms\n",
    "# such as mapping a group of words to the same stem even if the stem itself is not valid\n",
    "# word in the Language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "928eeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d28354f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words (text):\n",
    "    return\"\".join([ps.stem (word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b5e2cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walkwalkwalkwalk'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9c95935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming mapping a group of words to the same stem even if the stem itself is not valid word in Langu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46b5415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='probably my alltime favourite movie a story of selflessness sacrifice and dedication.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b624ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably my alltime favourite movie a story of selflessness sacrifice and dedication.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5958bba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3753409943.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\deepak\\AppData\\Local\\Temp\\ipykernel_17432\\3753409943.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    : # Lemmatization, unlike Stemming, reduces the inflected words properly ensuring that\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ": # Lemmatization, unlike Stemming, reduces the inflected words properly ensuring that\n",
    "    #the root word belongs to the Language.\n",
    "#     In Lemitization root word is called Lemma.\n",
    "#ALemma (plural Lemmas or Lemmata) is the canonical form, dictionary form, or citation form of a set\n",
    "# Stemming works on beehalf algorithm so it is fast and Lemmatization is using wordnet package, SO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0abf55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\deepak\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43b7ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5212079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "was                 wa                  \n",
      "and                 and                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "He                  He                  \n",
      "bad                 bad                 \n",
      "of                  of                  \n",
      "after               after               \n",
      "long                long                \n",
      "in                  in                  \n",
      "sun                 sun                 \n"
     ]
    }
   ],
   "source": [
    "sentence = \"He was running and eating at the same time He has bad habbit of swimming after playing long hours in the sun\"\n",
    "punctuation = ' ?:!. ,;'\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    sentence_words.remove(word)\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\" , \"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word , wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88af3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
